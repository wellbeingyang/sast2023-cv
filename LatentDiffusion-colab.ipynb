{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e50b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6073b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'sast2023-cv'...\n",
      "fatal: unable to access 'https://github.com/wellbeingyang/sast2023-cv/': OpenSSL SSL_read: Connection was reset, errno 10054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning==2.0.5\n",
      "  Using cached lightning-2.0.5-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (2.1.1)\n",
      "Collecting diffusers\n",
      "  Using cached diffusers-0.19.3-py3-none-any.whl (1.3 MB)\n",
      "Collecting einops\n",
      "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: imageio in d:\\anaconda\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: scikit-image in d:\\anaconda\\lib\\site-packages (0.20.0)\n",
      "Collecting kornia\n",
      "  Using cached kornia-0.6.12-py2.py3-none-any.whl (653 kB)\n",
      "Requirement already satisfied: Jinja2<5.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (3.1.2)\n",
      "Requirement already satisfied: PyYAML<8.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (6.0)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (1.2.3)\n",
      "Collecting backoff<4.0,>=2.2.1 (from lightning==2.0.5)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (4.12.2)\n",
      "Requirement already satisfied: click<10.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (8.0.4)\n",
      "Collecting croniter<1.5.0,>=1.3.0 (from lightning==2.0.5)\n",
      "  Using cached croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting dateutils<2.0 (from lightning==2.0.5)\n",
      "  Using cached dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Collecting deepdiff<8.0,>=5.7.0 (from lightning==2.0.5)\n",
      "  Using cached deepdiff-6.3.1-py3-none-any.whl (70 kB)\n",
      "Collecting fastapi<2.0,>=0.92.0 (from lightning==2.0.5)\n",
      "  Downloading fastapi-0.100.1-py3-none-any.whl (65 kB)\n",
      "                                              0.0/65.8 kB ? eta -:--:--\n",
      "     ------                                   10.2/65.8 kB ? eta -:--:--\n",
      "     ------                                   10.2/65.8 kB ? eta -:--:--\n",
      "     -----------------------                41.0/65.8 kB 326.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 65.8/65.8 kB 444.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (2023.3.0)\n",
      "Collecting inquirer<5.0,>=2.10.0 (from lightning==2.0.5)\n",
      "  Using cached inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
      "Collecting lightning-cloud>=0.5.37 (from lightning==2.0.5)\n",
      "  Using cached lightning_cloud-0.5.37-py3-none-any.whl (596 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.7.0 (from lightning==2.0.5)\n",
      "  Using cached lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (23.0)\n",
      "Requirement already satisfied: psutil<7.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (5.9.0)\n",
      "Collecting pydantic<2.0.0,>=1.7.4 (from lightning==2.0.5)\n",
      "  Using cached pydantic-1.10.12-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Collecting python-multipart<2.0,>=0.0.5 (from lightning==2.0.5)\n",
      "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: requests<4.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (2.29.0)\n",
      "Collecting rich<15.0,>=12.3.0 (from lightning==2.0.5)\n",
      "  Downloading rich-13.5.1-py3-none-any.whl (239 kB)\n",
      "                                              0.0/239.7 kB ? eta -:--:--\n",
      "     ------                                  41.0/239.7 kB 2.0 MB/s eta 0:00:01\n",
      "     --------------                          92.2/239.7 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------         194.6/239.7 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 239.7/239.7 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting starlette (from lightning==2.0.5)\n",
      "  Downloading starlette-0.31.0-py3-none-any.whl (69 kB)\n",
      "                                              0.0/69.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 69.8/69.8 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting starsessions<2.0,>=1.2.1 (from lightning==2.0.5)\n",
      "  Using cached starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting torch<4.0,>=1.11.0 (from lightning==2.0.5)\n",
      "  Using cached torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)\n",
      "Collecting torchmetrics<2.0,>=0.7.0 (from lightning==2.0.5)\n",
      "  Using cached torchmetrics-1.0.1-py3-none-any.whl (729 kB)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (4.65.0)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (5.7.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (4.6.3)\n",
      "Requirement already satisfied: urllib3<4.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (1.26.16)\n",
      "Collecting uvicorn<2.0 (from lightning==2.0.5)\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "                                              0.0/59.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 59.5/59.5 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: websocket-client<3.0 in d:\\anaconda\\lib\\site-packages (from lightning==2.0.5) (0.58.0)\n",
      "Collecting websockets<13.0 (from lightning==2.0.5)\n",
      "  Using cached websockets-11.0.3-cp311-cp311-win_amd64.whl (124 kB)\n",
      "Collecting pytorch-lightning (from lightning==2.0.5)\n",
      "  Using cached pytorch_lightning-2.0.6-py3-none-any.whl (722 kB)\n",
      "Requirement already satisfied: boto3 in d:\\anaconda\\lib\\site-packages (from transformers) (1.24.28)\n",
      "Requirement already satisfied: regex in d:\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting sentencepiece (from transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "Requirement already satisfied: sacremoses in d:\\anaconda\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: importlib-metadata in d:\\anaconda\\lib\\site-packages (from diffusers) (6.0.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from diffusers) (3.9.0)\n",
      "Collecting huggingface-hub>=0.13.2 (from diffusers)\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting safetensors>=0.3.1 (from diffusers)\n",
      "  Using cached safetensors-0.3.1-cp311-cp311-win_amd64.whl (263 kB)\n",
      "Requirement already satisfied: Pillow in d:\\anaconda\\lib\\site-packages (from diffusers) (9.4.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch<4.0,>=1.11.0->lightning==2.0.5) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch<4.0,>=1.11.0->lightning==2.0.5) (2.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.8 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\anaconda\\lib\\site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning==2.0.5) (2.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click<10.0->lightning==2.0.5) (0.4.6)\n",
      "Requirement already satisfied: pytz in d:\\anaconda\\lib\\site-packages (from dateutils<2.0->lightning==2.0.5) (2022.7)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning==2.0.5)\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting starlette (from lightning==2.0.5)\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\anaconda\\lib\\site-packages (from fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (3.8.3)\n",
      "Collecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning==2.0.5)\n",
      "  Using cached blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning==2.0.5)\n",
      "  Using cached python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning==2.0.5)\n",
      "  Using cached readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from Jinja2<5.0->lightning==2.0.5) (2.1.1)\n",
      "Requirement already satisfied: pyjwt in d:\\anaconda\\lib\\site-packages (from lightning-cloud>=0.5.37->lightning==2.0.5) (2.4.0)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from lightning-cloud>=0.5.37->lightning==2.0.5) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<4.0->lightning==2.0.5) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<4.0->lightning==2.0.5) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<4.0->lightning==2.0.5) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda\\lib\\site-packages (from rich<15.0,>=12.3.0->lightning==2.0.5) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda\\lib\\site-packages (from rich<15.0,>=12.3.0->lightning==2.0.5) (2.15.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in d:\\anaconda\\lib\\site-packages (from starlette->lightning==2.0.5) (3.5.0)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in d:\\anaconda\\lib\\site-packages (from starsessions<2.0,>=1.2.1->lightning==2.0.5) (2.0.1)\n",
      "Collecting h11>=0.8 (from uvicorn<2.0->lightning==2.0.5)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in d:\\anaconda\\lib\\site-packages (from boto3->transformers) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in d:\\anaconda\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in d:\\anaconda\\lib\\site-packages (from boto3->transformers) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata->diffusers) (3.11.0)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda\\lib\\site-packages (from anyio<5,>=3.4.0->starlette->lightning==2.0.5) (1.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in d:\\anaconda\\lib\\site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning==2.0.5) (0.2.5)\n",
      "Collecting jinxed>=1.1.0 (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning==2.0.5)\n",
      "  Using cached jinxed-1.2.0-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning==2.0.5) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0 in d:\\anaconda\\lib\\site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning==2.0.5) (67.8.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch<4.0,>=1.11.0->lightning==2.0.5) (1.2.1)\n",
      "Collecting ansicon (from jinxed>=1.1.0->blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning==2.0.5)\n",
      "  Using cached ansicon-1.89.0-py2.py3-none-any.whl (63 kB)\n",
      "Installing collected packages: sentencepiece, safetensors, python-editor, ansicon, websockets, readchar, python-multipart, pydantic, ordered-set, lightning-utilities, jinxed, h11, einops, backoff, uvicorn, torch, starlette, rich, huggingface-hub, deepdiff, dateutils, croniter, blessed, torchvision, torchmetrics, starsessions, kornia, inquirer, fastapi, diffusers, pytorch-lightning, lightning-cloud, lightning\n",
      "Successfully installed ansicon-1.89.0 backoff-2.2.1 blessed-1.20.0 croniter-1.4.1 dateutils-0.6.12 deepdiff-6.3.1 diffusers-0.19.3 einops-0.6.1 fastapi-0.100.1 h11-0.14.0 huggingface-hub-0.16.4 inquirer-3.1.3 jinxed-1.2.0 kornia-0.6.12 lightning-2.0.5 lightning-cloud-0.5.37 lightning-utilities-0.9.0 ordered-set-4.1.0 pydantic-1.10.12 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.6 readchar-4.0.5 rich-13.5.1 safetensors-0.3.1 sentencepiece-0.1.99 starlette-0.27.0 starsessions-1.3.0 torch-2.0.1 torchmetrics-1.0.1 torchvision-0.15.2 uvicorn-0.23.2 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wellbeingyang/sast2023-cv\n",
    "!pip install lightning==2.0.5 transformers diffusers einops torchvision numpy matplotlib imageio scikit-image kornia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce528bb2",
   "metadata": {},
   "source": [
    "# Latent Diffusion Training\n",
    "\n",
    "In this notebook, we will train a simple `LatentDiffusion` model.\n",
    "\n",
    "The training should take up to 20 hours for reasonable results.\n",
    "\n",
    "Ideally, you will download this dataset once and store it as `./afhq`. If you're running on colab, it's a good idea to download it once to your personal machine (it's only 240 MB) and then upload it to your colab space when you start a new notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./sast2023-cv/')\n",
    "sys.argv = ['ipykernel_launcher.py']\n",
    "\n",
    "import os, sys, argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from src import *\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Actually it's totally unnecessay and silly to use argparse in jupyter notebook. \n",
    "# But anyway, it's a good chance to do some practice and it will definitey be useful someday.\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--image_size\", type=int, default=256, help=\"Image size\")\n",
    "parser.add_argument(\"--train_dataset\", type=str, default=\"./afhq/\", help=\"The path to your training dataset\")\n",
    "parser.add_argument(\"--device\", type=str, default=0 if torch.cuda.is_available() else \"cpu\", help=\"Device number.\")\n",
    "parser.add_argument(\"--num_workers\", type=int, default=0, help=\"Spawn how many processes to load data.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help='manual seed')\n",
    "parser.add_argument(\"--max_epochs\", type=int, default=1000, help=\"Max epoch number to run.\")\n",
    "parser.add_argument(\"--ckpt_path\", type=str, default=\"\", help=\"Checkpoint path to load.\")\n",
    "parser.add_argument(\"--save_path\", type=str, default=\"./ckpt/\", help=\"Checkpoint path to save.\")\n",
    "parser.add_argument(\"--save_freq\", type=int, default=1, help=\"Save model every how many epochs.\")\n",
    "parser.add_argument(\"--ddim_steps\", type=int, default=50, help=\"DDIM timesteps\")\n",
    "# TODO begin: Add arguments lr and batch_size. It's recommended to set default lr to 1e-4 and default batch_size to 8.\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"Learning rate.\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=8, help=\"The batch size.\")\n",
    "# TODO end\n",
    "args = parser.parse_args()\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ec7fb",
   "metadata": {},
   "source": [
    "### Prepare dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.utils import image_to_tensor\n",
    "import kornia.augmentation as KA\n",
    "\n",
    "class SimpleImageDataset(Dataset):\n",
    "    \"\"\"Dataset returning images in a folder.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 transforms = None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # set up transforms\n",
    "        if self.transforms is not None:\n",
    "            data_keys = ['input']\n",
    "\n",
    "            self.input_T = KA.container.AugmentationSequential(\n",
    "                *self.transforms,\n",
    "                data_keys = data_keys,\n",
    "                same_on_batch = False\n",
    "            )\n",
    "\n",
    "        # TODO begin: Define the image paths filtered by the `supported_formats` in your datasets\n",
    "        # Hint: os.listdir\n",
    "        # Challenge: Can you complete this task in one line? (hint: Python comprehension, refer to Python basics handout by Yifan Li)\n",
    "        supported_formats = [\"jpg\", \"png\"]\n",
    "        self.image_names = [path for path in os.listdir(args.train_dataset) if path[-3:] == any(supported_formats)]\n",
    "        # TODO end\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO begin: Return the length of your dataset\n",
    "        return len(self.image_names)\n",
    "        # TODO end\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.image_names[idx])\n",
    "        image = image_to_tensor(imageio.imread(img_name)) / 255\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.input_T(image)[0]\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "CROP_SIZE = args.image_size\n",
    "\n",
    "transform = [\n",
    "    KA.RandomCrop((2 * CROP_SIZE,2 * CROP_SIZE)),\n",
    "    KA.Resize((CROP_SIZE, CROP_SIZE), antialias=True),\n",
    "    KA.RandomVerticalFlip()\n",
    "  ]\n",
    "\n",
    "train_dataset = SimpleImageDataset(args.train_dataset, transforms = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO begin: Define the training dataloader using torch.utils.data.DataLoader\n",
    "# Hint: check the API of torch.utils.data.DataLoader, especially arguments like batch_size, shuffle, num_workers\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers\n",
    "    )\n",
    "# TODO end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e372cc",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04156f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "\n",
    "# TODO begin: complete the LatentDiffusion Model in `src`\n",
    "model = LatentDiffusion(lr = args.lr, batch_size = args.batch_size)\n",
    "# TODO end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f33e5",
   "metadata": {},
   "source": [
    "...but first, let's check if the used `AutoEncoder` (`model.vae`) can reconstruct our samples well.\n",
    "\n",
    "**You should always test your autoencoder in this way when using latent diffusion models on a new dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_dataset[0]\n",
    "\n",
    "# TODO begin: Show the example img and use vae to reconstruct it using matplotlib\n",
    "# Hint: plt.imshow\n",
    "# Challenge: What's the image shape here? Should you permute or unsqueeze it?\n",
    "plt.figure()\n",
    "plt.imshow\n",
    "plt.subplot(1,2,1)\n",
    "# Plot the original img here\n",
    "\n",
    "plt.title('Input')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# Plot the reconstructed img by `mode.vae` here\n",
    "\n",
    "plt.title('AutoEncoder Reconstruction')\n",
    "# TODO end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer using PyTorch Lightning\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=args.save_path, every_n_epochs=args.save_freq)\n",
    "\n",
    "# TODO: You can specify other parameters here, like accelerator, devices...\n",
    "# You can check the pl.Trainer API here: https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = args.max_epochs,\n",
    "    callbacks = [EMA(0.9999), checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deafb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy to train the model in PyTorch Lightning in one line\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, ckpt_path=args.ckpt_path if args.ckpt_path else None)\n",
    "# TODO Challenge: Can you add some logging and visualization codes to better babysitting the training process? \n",
    "# Hint: There are many librarys you can use, e.g. logging, tensorboard, wandb... And the easiest way: print the loss every step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d9c71",
   "metadata": {},
   "source": [
    "Go to sleep now ~ This one line might run for days...\n",
    "\n",
    "Wait! Please make sure that you have save the checkpoints correctly. \n",
    "\n",
    "If the code breaks for some reason, you can load the checkpoint and continue training.\n",
    "\n",
    "### Now sample images from your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4faf7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(args.device)\n",
    "out = model(batch_size = args.batch_size, shape = (64,64), verbose = True)\n",
    "# You can also try `sampler=DDIM_Sampler(num_steps=args.ddim_steps)`, which can sample images in less than 50 steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeddad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(out.shape[0]):\n",
    "    plt.subplot(1,len(out),idx+1)\n",
    "    plt.imshow(out[idx].detach().cpu().permute(1,2,0))\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
